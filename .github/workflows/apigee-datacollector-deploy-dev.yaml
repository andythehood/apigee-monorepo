# This workflow deploys ApigeeX Data Collectors

name: Deploy ApigeeX Datacollectors

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the "main" branch
  push:
    branches: [ "main" ]
    paths:
      - 'datacollectors/**'
  pull_request:
    branches: [ "main" ]
    paths:
      - 'datacollectors/**'

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

jobs:
  detect-changes:
    name: Detect Changes to Data Collectors
    runs-on: ubuntu-latest
    environment: dev
    outputs:
      datacollectors: ${{ steps.set-datacollectors.outputs.matrix }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Get changed files
        id: changed
        run: |
          echo "Detecting changed files..."
          echo "Event name: ${{ github.event_name }}"

          # Compare with the base commit (for PRs) or previous SHA (for push)
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            BASE=${{ github.event.pull_request.base.sha }}
          else
            BASE=${{ github.event.before }}
          fi

          CHANGED=$(git diff --name-only "$BASE" ${{ github.sha }} | xargs)

          echo "changed_files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Extract changed Data Collector folders
        id: set-datacollectors
        run: |
          FILES="${{ steps.changed.outputs.changed_files }}"

          DATACOLLECTORS=$(echo "$FILES" | tr ' ' '\n' | grep '^datacollectors/' | cut -d/ -f2 | sort -u | jq -R . | jq -s .)
          echo "matrix<<EOF" >> $GITHUB_OUTPUT
          echo "$DATACOLLECTORS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

  deploy-datacollectors:
    name: Deploy Changed Data Collectors
    needs: detect-changes
    if: needs.detect-changes.outputs.datacollectors != '[]'

    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    environment: dev
    env:
      DEPLOY_ENV: ${{ github.ref == 'refs/heads/main' && 'dev' || 'prod' }}
      APIGEE_X_ORG: ${{ vars.APIGEE_X_ORG }}
      APIGEE_X_ENVS: "public private"

    strategy:
      matrix:
        datacollector: ${{ fromJson(needs.detect-changes.outputs.datacollectors) }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      # The committed changes may have deleted the datacollector folder, so we need to check whether it still exists
      # If it does, then we proceed with the deployment
      # If it does not, we delete the Data Collectos from all environments
      - name: Check if Data Collector folder exists
        id: check_folder
        run: |
          if [ -d "datacollectors/${{ matrix.datacollector }}" ]; then
            echo "Data Collector folder exists"
            echo "exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "Folder does not exist"
            echo "exists=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Authenticate to Google Cloud
        id: auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.APIGEE_SA_KEY }}'

      - name: Install Apigee CLI
        run: |
          curl -sLO https://github.com/apigee/apigeecli/releases/download/v2.13.0/apigeecli_v2.13.0_Linux_x86_64.zip
          unzip apigeecli_v2.13.0_Linux_x86_64.zip
          sudo mv apigeecli_v2.13.0_Linux_x86_64/apigeecli /usr/local/bin/

      - name: Install yq
        run: |
          sudo wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/bin/yq
          sudo chmod +x /usr/bin/yq

      - name: Output Deployment Info
        if: steps.check_folder.outputs.exists == 'true'
        run: |
          echo "Preparing to deploy Data Collector ${{ matrix.datacollector }} to $APIGEE_X_ORG from branch ${{ github.ref_name }}"

      - name: Create ApigeeX Data Collector if it doesn't exist
        if: steps.check_folder.outputs.exists == 'true'
        run: |
          set +e  # disable immediate exit on error

          TYPE=$(cat "datacollectors/${{ matrix.datacollector }}/datacollector.yaml" | yq -r '.datacollector.type')

          OUTPUT=$(apigeecli datacollectors create --default-token -o "$APIGEE_X_ORG" --name ${{ matrix.datacollector }} --type $TYPE 2>&1) 
          STATUS=$?

          echo "$OUTPUT"
          if [ "$STATUS" -eq 0 ]; then
            echo "✅ Success"
          elif echo "$OUTPUT" | grep -q "already exists"; then
            echo "ℹ️ Already exists, treating as success"
          else
            echo "❌ Unexpected error"
            exit $STATUS
          fi

      # The committed changes have deleted the kvm, so we delete the datacollector from all environments          
      - name: Remove Deleted Data Collectors
        if: steps.check_folder.outputs.exists == 'false'
        run: |
          set +e  # disable immediate exit on error
          echo "Data Collector ${{ matrix.datacollector }} does not exist. Undeploying from all Environments."

          OUTPUT=$(apigeecli datacollectors delete --default-token -o "$APIGEE_X_ORG"  --name "${{ matrix.datacollector }}")
          STATUS=$?

          if [ "$STATUS" -eq 0 ]; then
            echo "✅ Success"
          elif echo "$OUTPUT" | grep -q "not found"; then
            echo "ℹ️ KVM is not deployed to this environment, so ignoring delete"
          else
            echo "❌ Unexpected error"
            exit $STATUS
          fi
